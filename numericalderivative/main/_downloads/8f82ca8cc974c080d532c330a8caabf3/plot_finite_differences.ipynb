{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Use the finite differences formulas\n\nThis example shows how to use finite difference (F.D.) formulas.\n\n## References\n- M. Baudin (2023). M\u00e9thodes num\u00e9riques. Dunod.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numericalderivative as nd\nimport numpy as np\nimport pylab as pl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute the first derivative using forward F.D. formula\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the function we want to compute the derivative of.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def scaled_exp(x):\n    alpha = 1.0e6\n    return np.exp(-x / alpha)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the F.D. formula\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 1.0\nfinite_difference = nd.FirstDerivativeForward(scaled_exp, x)\nstep = 1.0e-3  # A first guess\nf_prime_approx = finite_difference.compute(step)\nprint(f\"Approximate f'(x) = {f_prime_approx}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To check our result, we define the exact first derivative.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def scaled_exp_prime(x):\n    alpha = 1.0e6\n    return -np.exp(-x / alpha) / alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the exact derivative and the absolute error.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "f_prime_exact = scaled_exp_prime(x)\nprint(f\"Exact f'(x) = {f_prime_exact}\")\nabsolute_error = abs(f_prime_approx - f_prime_exact)\nprint(f\"Absolute error = {absolute_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the error function: this will be useful later.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_absolute_error(step, x=1.0, verbose=True):\n    finite_difference = nd.FirstDerivativeForward(scaled_exp, x)\n    f_prime_approx = finite_difference.compute(step)\n    f_prime_exact = scaled_exp_prime(x)\n    absolute_error = abs(f_prime_approx - f_prime_exact)\n    if verbose:\n        print(f\"Approximate f'(x) = {f_prime_approx}\")\n        print(f\"Exact f'(x) = {f_prime_exact}\")\n        print(f\"Absolute error = {absolute_error}\")\n    return absolute_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute the exact step for the forward F.D. formula\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This step depends on the second derivative.\nFirstly, we assume that this is unknown and use a first\nguess of it, equal to 1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "second_derivative_value = 1.0\nstep, absolute_error = nd.FirstDerivativeForward.compute_step(second_derivative_value)\nprint(f\"Approximately optimal step (using f''(x) = 1) = {step}\")\nprint(f\"Approximately absolute error = {absolute_error}\")\n_ = compute_absolute_error(step, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the new step is much better than the our initial guess:\nthe approximately optimal step is much smaller, which leads to a smaller\nabsolute error.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our particular example, the second derivative is known: let's use\nthis information and compute the exactly optimal step.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def scaled_exp_2nd_derivative(x):\n    alpha = 1.0e6\n    return np.exp(-x / alpha) / (alpha**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "second_derivative_value = scaled_exp_2nd_derivative(x)\nprint(f\"Exact second derivative f''(x) = {second_derivative_value}\")\nstep, absolute_error = nd.FirstDerivativeForward.compute_step(second_derivative_value)\nprint(f\"Approximately optimal step (using f''(x) = 1) = {step}\")\nprint(f\"Approximately absolute error = {absolute_error}\")\n_ = compute_absolute_error(step, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_step_sensitivity(\n    finite_difference,\n    x,\n    function_derivative,\n    step_array,\n    higher_derivative_value,\n    relative_error=1.0e-16,\n):\n    \"\"\"\n    Compute the approximate derivative using central F.D. formula.\n    Create a plot representing the absolute error depending on step.\n\n    Parameters\n    ----------\n    finite_difference : FiniteDifferenceFormula\n        The F.D. formula\n    x : float\n        The input point\n    function_derivative : function\n        The exact derivative of the function.\n    step_array : array(n_points)\n        The array of steps to consider\n    higher_derivative_value : float\n        The value of the higher derivative required for the optimal step for the derivative\n    \"\"\"\n    number_of_points = len(step_array)\n    error_array = np.zeros((number_of_points))\n    for i in range(number_of_points):\n        f_prime_approx = finite_difference.compute(step_array[i])\n        error_array[i] = abs(f_prime_approx - function_derivative(x))\n\n    pl.figure()\n    pl.plot(step_array, error_array, label=\"Computed\")\n    pl.title(finite_difference.__class__.__name__)\n    pl.xlabel(\"h\")\n    pl.ylabel(\"Error\")\n    pl.xscale(\"log\")\n    pl.legend(bbox_to_anchor=(1.0, 1.0))\n    pl.yscale(\"log\")\n\n    # Compute the error using the model\n    function = finite_difference.get_function().get_function()\n    absolute_precision_function_eval = abs(function(x)) * relative_error\n    error_array = np.zeros((number_of_points))\n    for i in range(number_of_points):\n        error_array[i] = finite_difference.compute_error(\n            step_array[i], higher_derivative_value, absolute_precision_function_eval\n        )\n\n    pl.plot(step_array, error_array, \"--\", label=\"Model\")\n    # Compute the optimal step size and optimal error\n    optimal_step, absolute_error = finite_difference.compute_step(\n        higher_derivative_value, absolute_precision_function_eval\n    )\n    pl.plot([optimal_step], [absolute_error], \"o\", label=r\"$(h^*, e(h^*))$\")\n    #\n    pl.tight_layout()\n    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the forward F.D. formula, the absolute error is known if the\nsecond derivative value can be computed.\nThe next script uses this feature from the `compute_error()` method\nto plot the upper bound of the error.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_points = 1000\nstep_array = np.logspace(-10.0, 5.0, number_of_points)\nfinite_difference = nd.FirstDerivativeForward(scaled_exp, x)\nplot_step_sensitivity(\n    finite_difference, x, scaled_exp_prime, step_array, second_derivative_value\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These features are available with most F.D. formulas:\nthe next sections show how the module provides the exact\noptimal step and the exact error for other formulas.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Central F.D. formula for first derivative\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us see how this behaves with central F.D.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For the central F.D. formula, the exact step depends on the\n# third derivative\ndef scaled_exp_3d_derivative(x):\n    alpha = 1.0e6\n    return -np.exp(-x / alpha) / (alpha**3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_points = 1000\nstep_array = np.logspace(-10.0, 5.0, number_of_points)\nfinite_difference = nd.FirstDerivativeCentral(scaled_exp, x)\nthird_derivative_value = scaled_exp_3d_derivative(x)\nplot_step_sensitivity(\n    finite_difference, x, scaled_exp_prime, step_array, third_derivative_value\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Central F.D. formula for second derivative\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us see how this behaves with central F.D. for the second derivative.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the central F.D. formula of the second derivative, the exact step depends on the\nfourth derivative\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def scaled_exp_4th_derivative(x):\n    alpha = 1.0e6\n    return np.exp(-x / alpha) / (alpha**4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_points = 1000\nstep_array = np.logspace(-5.0, 7.0, number_of_points)\nfinite_difference = nd.SecondDerivativeCentral(scaled_exp, x)\nfourth_derivative_value = scaled_exp_4th_derivative(x)\nplot_step_sensitivity(\n    finite_difference, x, scaled_exp_2nd_derivative, step_array, fourth_derivative_value\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Central F.D. formula for third derivative\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us see how this behaves with central F.D. for the third derivative.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the central F.D. formula of the third derivative, the exact step depends on the\nfifth derivative\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def scaled_exp_5th_derivative(x):\n    alpha = 1.0e6\n    return np.exp(-x / alpha) / (alpha**5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_points = 1000\nstep_array = np.logspace(-5.0, 7.0, number_of_points)\nfinite_difference = nd.ThirdDerivativeCentral(scaled_exp, x)\nfifth_derivative_value = scaled_exp_5th_derivative(x)\nplot_step_sensitivity(\n    finite_difference, x, scaled_exp_3d_derivative, step_array, fifth_derivative_value\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}