{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Benchmark Stepleman & Winarsky's method\n\nFind a step which is near to optimal for a centered finite difference \nformula.\n\n## References\n- Adaptive numerical differentiation\n  R. S. Stepleman and N. D. Winarsky\n  Journal: Math. Comp. 33 (1979), 1257-1264 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pylab as pl\nimport tabulate\nimport numericalderivative as nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_first_derivative_SW(\n    f,\n    x,\n    initial_step,\n    f_prime,\n    beta=4.0,\n    verbose=False,\n):\n    \"\"\"\n    Compute the approximate derivative from finite differences\n\n    Uses bisection to find the approximate optimal step for the first\n    derivative.\n\n    Parameters\n    ----------\n    f : function\n        The function.\n    x : float\n        The point where the derivative is to be evaluated\n    initial_step : float, > 0\n        A initial step.\n    f_prime : function\n        The exact first derivative of the function.\n    beta : float, > 1.0\n        The reduction factor of h at each iteration.\n    verbose : bool, optional\n        Set to True to print intermediate messages. The default is False.\n\n    Returns\n    -------\n    absolute_error : float, > 0\n        The absolute error between the approximate first derivative\n        and the true first derivative.\n\n    feval : int\n        The number of function evaluations.\n    \"\"\"\n    algorithm = nd.SteplemanWinarsky(f, x, verbose=verbose)\n    step, _ = algorithm.compute_step(\n        initial_step,\n        beta=beta,\n    )\n    f_prime_approx = algorithm.compute_first_derivative(step)\n    feval = algorithm.get_number_of_function_evaluations()\n    absolute_error = abs(f_prime_approx - f_prime(x))\n    return absolute_error, feval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bracket_step = [1.0e-7, 1.0e1]\nx = 1.0\nbenchmark = nd.ExponentialDerivativeBenchmark()\nalgorithm = nd.SteplemanWinarsky(\n    benchmark.function,\n    x,\n    verbose=True,\n)\noptimal_step_formula = nd.FiniteDifferenceOptimalStep()\nthird_derivative_value = benchmark.third_derivative(x)\noptimal_step, absolute_error = (\n    optimal_step_formula.compute_step_first_derivative_central(third_derivative_value)\n)\nprint(\"Exact h* = %.3e\" % (optimal_step))\n\nh0, iterations = algorithm.search_step_with_bisection(\n    bracket_step,\n)\nprint(\"Pas initial = \", h0, \", iterations = \", iterations)\nlost_digits = algorithm.number_of_lost_digits(h0)\nprint(\"lost_digits = \", lost_digits)\n\ninitial_step = 1.0e1\nx = 1.0\n(\n    absolute_error,\n    number_of_function_evaluations,\n) = compute_first_derivative_SW(\n    benchmark.function,\n    x,\n    initial_step,\n    benchmark.first_derivative,\n    beta=10.0,\n    verbose=True,\n)\nprint(\n    \"x = %.3f, error = %.3e, Func. eval. = %d\"\n    % (x, absolute_error, number_of_function_evaluations)\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def benchmark_method(\n    function, derivative_function, test_points, initial_step, verbose=False\n):\n    \"\"\"\n    Apply Stepleman & Winarsky method to compute the approximate first\n    derivative using finite difference formula.\n\n    Parameters\n    ----------\n    f : function\n        The function.\n    derivative_function : function\n        The exact first derivative of the function\n    test_points : list(float)\n        The list of x points where the benchmark must be performed.\n    initial_step : float, > 0\n        The initial step.\n    verbose : bool, optional\n        Set to True to print intermediate messages. The default is False.\n\n    Returns\n    -------\n    absolute_error : float, > 0\n        The absolute error between the approximate first derivative\n        and the true first derivative.\n\n    feval : int\n        The number of function evaluations.\n\n    \"\"\"\n    number_of_test_points = len(test_points)\n    relative_error_array = np.zeros(number_of_test_points)\n    feval_array = np.zeros(number_of_test_points)\n    for i in range(number_of_test_points):\n        x = test_points[i]\n        (\n            absolute_error,\n            number_of_function_evaluations,\n        ) = compute_first_derivative_SW(\n            function,\n            x,\n            initial_step,\n            derivative_function,\n        )\n        relative_error = absolute_error / abs(derivative_function(x))\n        if verbose:\n            print(\n                \"x = %.3f, abs. error = %.3e, rel. error = %.3e, Func. eval. = %d\"\n                % (x, absolute_error, relative_error, number_of_function_evaluations)\n            )\n        relative_error_array[i] = relative_error\n        feval_array[i] = number_of_function_evaluations\n\n    average_relative_error = np.mean(relative_error_array)\n    average_feval = np.mean(feval_array)\n    if verbose:\n        print(\"Average error =\", average_relative_error)\n        print(\"Average number of function evaluations =\", average_feval)\n    return average_relative_error, average_feval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"+ Benchmark on several points\")\nnumber_of_test_points = 100\ntest_points = np.linspace(0.01, 12.2, number_of_test_points)\ninitial_step = 1.0e-1\nbenchmark = nd.ExponentialDerivativeBenchmark()\naverage_relative_error, average_feval = benchmark_method(\n    benchmark.function, benchmark.first_derivative, test_points, initial_step, True\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "function_list = [\n    [nd.ExponentialDerivativeBenchmark(), 1.0e-1],\n    [nd.LogarithmicDerivativeBenchmark(), 1.0e-3],  # x > 0\n    [nd.SquareRootDerivativeBenchmark(), 1.0e-3],  # x > 0\n    [nd.AtanDerivativeBenchmark(), 1.0e0],\n    [nd.SinDerivativeBenchmark(), 1.0e0],\n    [nd.ScaledExponentialDerivativeBenchmark(), 1.0e5],\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Benchmark SteplemanWinarsky\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_test_points = 100\ntest_points = np.linspace(0.01, 12.5, number_of_test_points)\ndata = []\nnumber_of_functions = len(function_list)\naverage_relative_error_list = []\naverage_feval_list = []\nfor i in range(number_of_functions):\n    benchmark, initial_step = function_list[i]\n    name = benchmark.name\n    average_relative_error, average_feval = benchmark_method(\n        benchmark.function, benchmark.first_derivative, test_points, initial_step\n    )\n    average_relative_error_list.append(average_relative_error)\n    average_feval_list.append(average_feval)\n    data.append(\n        (\n            name,\n            initial_step,\n            average_relative_error,\n            average_feval,\n        )\n    )\ndata.append(\n    [\"Average\", \"-\", np.mean(average_relative_error_list), np.mean(average_feval_list)]\n)\ntabulate.tabulate(\n    data,\n    headers=[\"Name\", \"h0\", \"Average rel. error\", \"Average func. eval\"],\n    tablefmt=\"html\",\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}