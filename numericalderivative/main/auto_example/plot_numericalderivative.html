<!DOCTYPE html>

<html lang="python" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>A simple demonstration of the methods &#8212; numericalderivative 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <script src="../_static/documentation_options.js?v=8cfa8c60"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="icon" href="../_static/Icon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Applies Stepleman &amp; Winarsky method to an OpenTURNS function" href="plot_openturns.html" />
    <link rel="prev" title="Examples" href="../examples/examples.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-example-plot-numericalderivative-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="a-simple-demonstration-of-the-methods">
<span id="sphx-glr-auto-example-plot-numericalderivative-py"></span><h1>A simple demonstration of the methods<a class="headerlink" href="#a-simple-demonstration-of-the-methods" title="Link to this heading">¶</a></h1>
<p>Finds a step which is near to optimal for a centered finite difference
formula.</p>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>Adaptive numerical differentiation. R. S. Stepleman and N. D. Winarsky. Journal: Math. Comp. 33 (1979), 1257-1264</p></li>
</ul>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pylab</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">import</span> <span class="nn">numericalderivative</span> <span class="k">as</span> <span class="nn">nd</span>
</pre></div>
</div>
<p>Define a function
Here, we do not use the ScaledExponentialDerivativeBenchmark class, for demonstration purposes</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">scaled_exp</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0e6</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
<p>Define its exact derivative (for testing purposes only)</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">scaled_exp_prime</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0e6</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="n">alpha</span>
</pre></div>
</div>
<p>Define its exact second derivative (for testing purposes only)</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">scaled_exp_second</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0e6</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="n">alpha</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
<p>Function value</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;+ Function&quot;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="mf">1.0e0</span>
<span class="n">exact_f_value</span> <span class="o">=</span> <span class="n">scaled_exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;exact_f_value = &quot;</span><span class="p">,</span> <span class="n">exact_f_value</span><span class="p">)</span>
<span class="n">exact_f_prime_value</span> <span class="o">=</span> <span class="n">scaled_exp_prime</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;exact_f_prime_value = &quot;</span><span class="p">,</span> <span class="n">exact_f_prime_value</span><span class="p">)</span>
<span class="n">exact_f_second_value</span> <span class="o">=</span> <span class="n">scaled_exp_second</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;exact_f_second_value = &quot;</span><span class="p">,</span> <span class="n">exact_f_second_value</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>+ Function
exact_f_value =  0.9999990000005
exact_f_prime_value =  -9.999990000005e-07
exact_f_second_value =  9.999990000005e-13
</pre></div>
</div>
<p>Algorithm to detect h*: SteplemanWinarsky</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;+ SteplemanWinarsky&quot;</span><span class="p">)</span>
<span class="n">h0</span> <span class="o">=</span> <span class="mf">1.0e5</span>
<span class="n">x</span> <span class="o">=</span> <span class="mf">1.0e0</span>
<span class="n">algorithm</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">SteplemanWinarsky</span><span class="p">(</span><span class="n">scaled_exp</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">h_optimal</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">compute_step</span><span class="p">(</span><span class="n">h0</span><span class="p">)</span>
<span class="n">number_of_function_evaluations</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">get_number_of_function_evaluations</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimum h =&quot;</span><span class="p">,</span> <span class="n">h_optimal</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;iterations =&quot;</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Function evaluations =&quot;</span><span class="p">,</span> <span class="n">number_of_function_evaluations</span><span class="p">)</span>
<span class="n">f_prime_approx</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">compute_first_derivative</span><span class="p">(</span><span class="n">h_optimal</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f_prime_approx = &quot;</span><span class="p">,</span> <span class="n">f_prime_approx</span><span class="p">)</span>
<span class="n">exact_f_prime_value</span> <span class="o">=</span> <span class="n">scaled_exp_prime</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;exact_f_prime_value = &quot;</span><span class="p">,</span> <span class="n">exact_f_prime_value</span><span class="p">)</span>
<span class="n">absolute_error</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">f_prime_approx</span> <span class="o">-</span> <span class="n">exact_f_prime_value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Absolute error = </span><span class="si">{</span><span class="n">absolute_error</span><span class="si">:</span><span class="s2">.3e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">relative_error</span> <span class="o">=</span> <span class="n">absolute_error</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">exact_f_prime_value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Relative error = </span><span class="si">{</span><span class="n">relative_error</span><span class="si">:</span><span class="s2">.3e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>+ SteplemanWinarsky
Optimum h = 1.52587890625
iterations = 8
Function evaluations = 20
f_prime_approx =  -9.999990000142134e-07
exact_f_prime_value =  -9.999990000005e-07
Absolute error = 1.371e-17
Relative error = 1.371e-11
</pre></div>
</div>
<p>Algorithm to detect h*: DumontetVignes</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;+ DumontetVignes&quot;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="mf">1.0e0</span>
<span class="n">algorithm</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">DumontetVignes</span><span class="p">(</span><span class="n">scaled_exp</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">h_optimal</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">compute_step</span><span class="p">(</span>
    <span class="n">kmin</span><span class="o">=</span><span class="mf">1.0e-2</span><span class="p">,</span>
    <span class="n">kmax</span><span class="o">=</span><span class="mf">1.0e2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">number_of_function_evaluations</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">get_number_of_function_evaluations</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimum h =&quot;</span><span class="p">,</span> <span class="n">h_optimal</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;iterations =&quot;</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Function evaluations =&quot;</span><span class="p">,</span> <span class="n">number_of_function_evaluations</span><span class="p">)</span>
<span class="n">f_prime_approx</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">compute_first_derivative</span><span class="p">(</span><span class="n">h_optimal</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f_prime_approx = &quot;</span><span class="p">,</span> <span class="n">f_prime_approx</span><span class="p">)</span>
<span class="n">exact_f_prime_value</span> <span class="o">=</span> <span class="n">scaled_exp_prime</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;exact_f_prime_value = &quot;</span><span class="p">,</span> <span class="n">exact_f_prime_value</span><span class="p">)</span>
<span class="n">absolute_error</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">f_prime_approx</span> <span class="o">-</span> <span class="n">exact_f_prime_value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Absolute error = </span><span class="si">{</span><span class="n">absolute_error</span><span class="si">:</span><span class="s2">.3e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">relative_error</span> <span class="o">=</span> <span class="n">absolute_error</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">exact_f_prime_value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Relative error = </span><span class="si">{</span><span class="n">relative_error</span><span class="si">:</span><span class="s2">.3e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>+ DumontetVignes
Optimum h = 31.05547598808822
iterations = 8
Function evaluations = 21
f_prime_approx =  -9.99999000162036e-07
exact_f_prime_value =  -9.999990000005e-07
Absolute error = 1.615e-16
Relative error = 1.615e-10
</pre></div>
</div>
<p>Algorithm to detect h*: GillMurraySaundersWright</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;+ GillMurraySaundersWright&quot;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="mf">1.0e0</span>
<span class="n">absolute_precision</span> <span class="o">=</span> <span class="mf">1.0e-15</span>
<span class="n">algorithm</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">GillMurraySaundersWright</span><span class="p">(</span><span class="n">scaled_exp</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">absolute_precision</span><span class="p">)</span>
<span class="n">kmin</span> <span class="o">=</span> <span class="mf">1.0e-2</span>
<span class="n">kmax</span> <span class="o">=</span> <span class="mf">1.0e7</span>
<span class="n">step</span><span class="p">,</span> <span class="n">number_of_iterations</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">compute_step</span><span class="p">(</span><span class="n">kmin</span><span class="p">,</span> <span class="n">kmax</span><span class="p">)</span>
<span class="n">number_of_function_evaluations</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">get_number_of_function_evaluations</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimum h for f&#39;=&quot;</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Function evaluations =&quot;</span><span class="p">,</span> <span class="n">number_of_function_evaluations</span><span class="p">)</span>
<span class="n">f_prime_approx</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">compute_first_derivative</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f_prime_approx = &quot;</span><span class="p">,</span> <span class="n">f_prime_approx</span><span class="p">)</span>
<span class="n">exact_f_prime_value</span> <span class="o">=</span> <span class="n">scaled_exp_prime</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;exact_f_prime_value = &quot;</span><span class="p">,</span> <span class="n">exact_f_prime_value</span><span class="p">)</span>
<span class="n">absolute_error</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">f_prime_approx</span> <span class="o">-</span> <span class="n">exact_f_prime_value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Absolute error = </span><span class="si">{</span><span class="n">absolute_error</span><span class="si">:</span><span class="s2">.3e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">relative_error</span> <span class="o">=</span> <span class="n">absolute_error</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">exact_f_prime_value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Relative error = </span><span class="si">{</span><span class="n">relative_error</span><span class="si">:</span><span class="s2">.3e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>+ GillMurraySaundersWright
Optimum h for f&#39;= 0.06324692604098761
Function evaluations = 12
f_prime_approx =  -9.999989694153764e-07
exact_f_prime_value =  -9.999990000005e-07
Absolute error = 3.059e-14
Relative error = 3.059e-08
</pre></div>
</div>
<p>Define a function with arguments</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_exp_with_args</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scaling</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span> <span class="o">/</span> <span class="n">scaling</span><span class="p">)</span>
</pre></div>
</div>
<p>Compute the derivative of a function with extra input arguments</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;+ Function with extra input arguments&quot;</span><span class="p">)</span>
<span class="n">h0</span> <span class="o">=</span> <span class="mf">1.0e5</span>
<span class="n">x</span> <span class="o">=</span> <span class="mf">1.0e0</span>
<span class="n">scaling</span> <span class="o">=</span> <span class="mf">1.0e6</span>
<span class="n">algorithm</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">SteplemanWinarsky</span><span class="p">(</span><span class="n">my_exp_with_args</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">[</span><span class="n">scaling</span><span class="p">])</span>
<span class="n">h_optimal</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">compute_step</span><span class="p">(</span><span class="n">h0</span><span class="p">)</span>
<span class="n">number_of_function_evaluations</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">get_number_of_function_evaluations</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimum h for f&#39;&#39;=&quot;</span><span class="p">,</span> <span class="n">h_optimal</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;iterations =&quot;</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Function evaluations =&quot;</span><span class="p">,</span> <span class="n">number_of_function_evaluations</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>+ Function with extra input arguments
Optimum h for f&#39;&#39;= 1.52587890625
iterations = 8
Function evaluations = 20
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 0.003 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-example-plot-numericalderivative-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/5059bdb6ebe7eed57c02f516a51fc640/plot_numericalderivative.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_numericalderivative.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c06f166361c9a810e26ad87bff405737/plot_numericalderivative.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_numericalderivative.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/e0de7a28e9370dd1ce335e4c8db9b7ea/plot_numericalderivative.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_numericalderivative.zip</span></code></a></p>
</div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">numericalderivative</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../user_manual/user_manual.html">User manual</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../examples/examples.html">Examples</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="../examples/examples.html">Examples</a><ul>
      <li>Previous: <a href="../examples/examples.html" title="previous chapter">Examples</a></li>
      <li>Next: <a href="plot_openturns.html" title="next chapter">Applies Stepleman &amp; Winarsky method to an OpenTURNS function</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;M. Baudin.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="../_sources/auto_example/plot_numericalderivative.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>