{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Experiment with Stepleman & Winarsky method\n\nFind a step which is near to optimal for a centered finite difference \nformula.\n\n## References\n- Adaptive numerical differentiation\n  R. S. Stepleman and N. D. Winarsky\n  Journal: Math. Comp. 33 (1979), 1257-1264 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pylab as pl\nimport numericalderivative as nd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider this problem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "benchmark = nd.ScaledExponentialProblem()\nname = benchmark.get_name()\nx = benchmark.get_x()\nthird_derivative = benchmark.get_third_derivative()\nthird_derivative_value = third_derivative(x)\noptimal_step_formula = nd.FiniteDifferenceOptimalStep()\noptimum_step, absolute_error = (\n    optimal_step_formula.compute_step_first_derivative_central(third_derivative_value)\n)\nprint(f\"Name = {name}, x = {x}\")\nprint(f\"Optimal step for central finite difference formula = {optimum_step}\")\nprint(f\"Minimum absolute error= {absolute_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Plot the error vs h\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 1.0\nfinite_difference = nd.FiniteDifferenceFormula(benchmark.function, x)\nnumber_of_points = 1000\nh_array = np.logspace(-7.0, 5.0, number_of_points)\nerror_array = np.zeros((number_of_points))\nfor i in range(number_of_points):\n    h = h_array[i]\n    f_prime_approx = finite_difference.compute_first_derivative_central(h)\n    error_array[i] = abs(f_prime_approx - benchmark.first_derivative(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pl.figure(figsize=(3.0, 2.0))\npl.plot(h_array, error_array)\npl.plot([optimum_step] * 2, [min(error_array), max(error_array)], label=r\"$h^*$\")\npl.title(\"Central finite difference\")\npl.xlabel(\"h\")\npl.ylabel(\"Error\")\npl.xscale(\"log\")\npl.yscale(\"log\")\npl.legend(bbox_to_anchor=(1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Algorithm to detect h*\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "algorithm = nd.SteplemanWinarsky(benchmark.function, x, verbose=True)\ninitial_step = 1.0e8\nx = 1.0e0\nh_optimal, iterations = algorithm.compute_step(initial_step)\nnumber_of_function_evaluations = algorithm.get_number_of_function_evaluations()\nprint(\"Optimum h =\", h_optimal)\nprint(\"iterations =\", iterations)\nprint(\"Function evaluations =\", number_of_function_evaluations)\nf_prime_approx = algorithm.compute_first_derivative(h_optimal)\nabsolute_error = abs(f_prime_approx - benchmark.first_derivative(x))\nprint(\"Error = \", absolute_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def fd_difference(h1, h2, f, x):\n    finite_difference = nd.FiniteDifferenceFormula(f, x)\n    f_prime_approx_1 = finite_difference.compute_first_derivative_central(h1)\n    f_prime_approx_2 = finite_difference.compute_first_derivative_central(h2)\n    diff_current = abs(f_prime_approx_1 - f_prime_approx_2)\n    return diff_current"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Plot the evolution of | FD(h) - FD(h / 2) | for different values of h\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_points = 1000\nh_array = np.logspace(-7.0, 5.0, number_of_points)\ndiff_array = np.zeros((number_of_points))\nfor i in range(number_of_points):\n    h = h_array[i]\n    diff_array[i] = fd_difference(h, h / 2, benchmark.function, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pl.figure(figsize=(3.0, 2.0))\npl.plot(h_array, diff_array)\npl.title(\"F.D. difference\")\npl.xlabel(\"h\")\npl.ylabel(r\"$|\\operatorname{FD}(h) - \\operatorname{FD}(h / 2) |$\")\npl.xscale(\"log\")\npl.yscale(\"log\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Plot the evolution of | FD(h) - FD(h / 2) | for different values of h\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_points = 20\nh_initial = 1.0e5\nbeta = 4.0\nh_array = np.zeros((number_of_points))\ndiff_array = np.zeros((number_of_points))\nfor i in range(number_of_points):\n    if i == 0:\n        h_array[i] = h_initial / beta\n        diff_array[i] = fd_difference(h_array[i], h_initial, benchmark.function, x)\n    else:\n        h_array[i] = h_array[i - 1] / beta\n        diff_array[i] = fd_difference(h_array[i], h_array[i - 1], benchmark.function, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pl.figure(figsize=(3.0, 2.0))\npl.plot(h_array, diff_array, \"o\")\npl.title(\"F.D. difference\")\npl.xlabel(\"h\")\npl.ylabel(r\"$|\\operatorname{FD}(h) - \\operatorname{FD}(h / 2) |$\")\npl.xscale(\"log\")\npl.yscale(\"log\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Compute suggested step\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p = 1.0e-16\nbeta = 4.0\nh_reference = beta * p ** (1 / 3) * x\nprint(\"Suggested h0 = \", h_reference)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Plot number of lost digits vs h\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h = 1.0e4\nprint(\"Starting h = \", h)\nn_digits = algorithm.number_of_lost_digits(h)\nprint(\"Number of lost digits = \", n_digits)\nthreshold = np.log10(p ** (-1.0 / 3.0) / beta)\nprint(\"Threshold = \", threshold)\n\nstep_zero, iterations = algorithm.search_step_with_bisection(\n    1.0e-5,\n    1.0e7,\n)\nprint(\"step_zero = \", step_zero)\nprint(\"iterations = \", iterations)\n\nestim_step, iterations = algorithm.compute_step(step_zero, beta=1.5)\nprint(\"estim_step = \", estim_step)\nprint(\"iterations = \", iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_points = 1000\nh_array = np.logspace(-7.0, 7.0, number_of_points)\nn_digits_array = np.zeros((number_of_points))\nfor i in range(number_of_points):\n    h = h_array[i]\n    n_digits_array[i] = algorithm.number_of_lost_digits(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_max = algorithm.number_of_lost_digits(h_reference)\npl.figure(figsize=(3.0, 2.0))\npl.plot(h_array, n_digits_array, label=\"$N(h)$\")\npl.plot([h_reference] * 2, [0.0, y_max], \"--\", label=r\"$h_{ref}$\")\npl.plot([step_zero] * 2, [0.0, y_max], \"--\", label=r\"$h^{(0)}$\")\npl.plot([estim_step] * 2, [0.0, y_max], \"--\", label=r\"$h^\\star$\")\npl.plot(\n    h_array,\n    np.array([threshold] * number_of_points),\n    \":\",\n    label=r\"$T$\",\n)\npl.title(\"Number of digits lost by F.D.\")\npl.xlabel(\"h\")\npl.ylabel(\"$N(h)$\")\npl.xscale(\"log\")\n_ = pl.legend(bbox_to_anchor=(1.1, 1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pl.figure(figsize=(3.0, 2.0))\npl.plot(h_array, error_array)\npl.plot([step_zero] * 2, [0.0, 1.0e-9], \"--\", label=r\"$h^{(0)}$\")\npl.plot([estim_step] * 2, [0.0, 1.0e-9], \"--\", label=r\"$h^\\star$\")\npl.title(\"Finite difference\")\npl.xlabel(\"h\")\npl.ylabel(\"Error\")\npl.xscale(\"log\")\npl.legend(bbox_to_anchor=(1.1, 1.0))\npl.yscale(\"log\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Benchmark\nTest with single point\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 1.0\nf_prime_approx, number_of_iterations = algorithm.search_step_with_bisection(\n    1.0e-7,\n    1.0e7,\n)\nfeval = algorithm.get_number_of_function_evaluations()\nprint(\"FD(x) = \", f_prime_approx)\nprint(\"number_of_iterations = \", number_of_iterations)\nprint(\"Func. eval = \", feval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algorithme de dichotomie pour le pas initial\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 1.0\nmaximum_bisection = 53\nlog_scale = False\nh0, iterations = algorithm.search_step_with_bisection(\n    1.0e-7,\n    1.0e1,\n    maximum_bisection=53,\n    log_scale=False,\n)\nprint(\"Pas initial = \", h0, \", iterations = \", iterations)\nh0, iterations = algorithm.search_step_with_bisection(\n    1.0e-7,\n    1.0e1,\n    maximum_bisection=53,\n    log_scale=True,\n)\nprint(\"Pas initial = \", h0, \", iterations = \", iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "benchmark = nd.ExponentialProblem()\nx = 1.0\nalgorithm = nd.SteplemanWinarsky(benchmark.function, x, verbose=True)\nf_prime_approx, estim_relative_error = algorithm.search_step_with_bisection(\n    1.0e-6,\n    100.0 * x,\n    beta=4.0,\n)\nabsolute_error = abs(f_prime_approx - benchmark.first_derivative(x))\nfeval = algorithm.get_number_of_function_evaluations()\nprint(\n    \"x = %.3f, abs. error = %.3e, estim. rel. error = %.3e, Func. eval. = %d\"\n    % (x, absolute_error, estim_relative_error, number_of_function_evaluations)\n)\n\n#"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}