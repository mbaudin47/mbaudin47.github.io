<!DOCTYPE html>

<html lang="python" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Experiment with Shi, Xie, Xuan &amp; Nocedal forward method &#8212; numericalderivative 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <script src="../_static/documentation_options.js?v=8cfa8c60"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="icon" href="../_static/Icon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Benchmark Shi, Xie, Xuan &amp; Nocedal&#39;s forward method" href="plot_shi_xie_xuan_nocedal_forward_benchmark.html" />
    <link rel="prev" title="Benchmark Stepleman &amp; Winarsky&#39;s method" href="plot_stepleman_winarsky_benchmark.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-example-plot-shi-xie-xuan-nocedal-forward-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="experiment-with-shi-xie-xuan-nocedal-forward-method">
<span id="sphx-glr-auto-example-plot-shi-xie-xuan-nocedal-forward-py"></span><h1>Experiment with Shi, Xie, Xuan &amp; Nocedal forward method<a class="headerlink" href="#experiment-with-shi-xie-xuan-nocedal-forward-method" title="Link to this heading">¶</a></h1>
<p>Find a step which is near to optimal for a forward finite difference
formula.</p>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>Shi, H. J. M., Xie, Y., Xuan, M. Q., &amp; Nocedal, J. (2022).
Adaptive finite-difference interval estimation for noisy derivative-free
optimization. SIAM Journal on Scientific Computing, 44 (4), A2302-A2321.</p></li>
</ul>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pylab</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">import</span> <span class="nn">numericalderivative</span> <span class="k">as</span> <span class="nn">nd</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="n">MaxNLocator</span>
</pre></div>
</div>
</section>
<section id="use-the-method-on-a-simple-problem">
<h2>Use the method on a simple problem<a class="headerlink" href="#use-the-method-on-a-simple-problem" title="Link to this heading">¶</a></h2>
<p>In the next example, we use the algorithm on the exponential function.
We create the <a class="reference internal" href="../user_manual/_generated/numericalderivative.ShiXieXuanNocedalForward.html#numericalderivative.ShiXieXuanNocedalForward" title="numericalderivative.ShiXieXuanNocedalForward"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShiXieXuanNocedalForward</span></code></a> algorithm using the function and the point x.
Then we use the <a class="reference internal" href="../user_manual/_generated/numericalderivative.ShiXieXuanNocedalForward.html#numericalderivative.ShiXieXuanNocedalForward.find_step" title="numericalderivative.ShiXieXuanNocedalForward.find_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">find_step()</span></code></a> method to compute the step,
using an upper bound of the step as an initial point of the algorithm.
Finally, use the <a class="reference internal" href="../user_manual/_generated/numericalderivative.ShiXieXuanNocedalForward.html#numericalderivative.ShiXieXuanNocedalForward.compute_first_derivative" title="numericalderivative.ShiXieXuanNocedalForward.compute_first_derivative"><code class="xref py py-meth docutils literal notranslate"><span class="pre">compute_first_derivative()</span></code></a> method to compute
an approximate value of the first derivative using finite differences.
The <a class="reference internal" href="../user_manual/_generated/numericalderivative.ShiXieXuanNocedalForward.html#numericalderivative.ShiXieXuanNocedalForward.get_number_of_function_evaluations" title="numericalderivative.ShiXieXuanNocedalForward.get_number_of_function_evaluations"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_number_of_function_evaluations()</span></code></a> method
can be used to get the number of function evaluations.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">algorithm</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">ShiXieXuanNocedalForward</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">initial_step</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">step</span><span class="p">,</span> <span class="n">number_of_iterations</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">find_step</span><span class="p">(</span><span class="n">initial_step</span><span class="p">)</span>
<span class="n">f_prime_approx</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">compute_first_derivative</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
<span class="n">feval</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">get_number_of_function_evaluations</span><span class="p">()</span>
<span class="n">f_prime_exact</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Since the derivative of exp is exp.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Computed step = </span><span class="si">{</span><span class="n">step</span><span class="si">:</span><span class="s2">.3e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of iterations = </span><span class="si">{</span><span class="n">number_of_iterations</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;f_prime_approx = </span><span class="si">{</span><span class="n">f_prime_approx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;f_prime_exact = </span><span class="si">{</span><span class="n">f_prime_exact</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">absolute_error</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">f_prime_approx</span> <span class="o">-</span> <span class="n">f_prime_exact</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>x = 1.0
f(x) = 2.718281828459045
f(x + h) = 7.38905609893065
f(x + 4 * h) = 148.4131591025766
absolute_precision = 1.000e-15
estim_step=1.000e+00
+ Iter.=0, lower_bound=0.000e+00, upper_bound=inf, estim_step=1.000e+00, r = 1.588e+16
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=1, lower_bound=0.000e+00, upper_bound=1.000e+00, estim_step=2.500e-01, r = 1.978e+14
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=2, lower_bound=0.000e+00, upper_bound=2.500e-01, estim_step=6.250e-02, r = 8.851e+12
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=3, lower_bound=0.000e+00, upper_bound=6.250e-02, estim_step=1.562e-02, r = 5.109e+11
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=4, lower_bound=0.000e+00, upper_bound=1.562e-02, estim_step=3.906e-03, r = 3.131e+10
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=5, lower_bound=0.000e+00, upper_bound=3.906e-03, estim_step=9.766e-04, r = 1.947e+09
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=6, lower_bound=0.000e+00, upper_bound=9.766e-04, estim_step=2.441e-04, r = 1.216e+08
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=7, lower_bound=0.000e+00, upper_bound=2.441e-04, estim_step=6.104e-05, r = 7.596e+06
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=8, lower_bound=0.000e+00, upper_bound=6.104e-05, estim_step=1.526e-05, r = 4.747e+05
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=9, lower_bound=0.000e+00, upper_bound=1.526e-05, estim_step=3.815e-06, r = 2.967e+04
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=10, lower_bound=0.000e+00, upper_bound=3.815e-06, estim_step=9.537e-07, r = 1.854e+03
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=11, lower_bound=0.000e+00, upper_bound=9.537e-07, estim_step=2.384e-07, r = 1.157e+02
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=12, lower_bound=0.000e+00, upper_bound=2.384e-07, estim_step=5.960e-08, r = 7.327e+00
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=13, lower_bound=0.000e+00, upper_bound=5.960e-08, estim_step=1.490e-08, r = 4.441e-01
    - test_ratio &lt; self.minimum_test_ratio. Set lower bound to h.
    - Bisection: estim_step = 2.980e-08.
+ Iter.=14, lower_bound=1.490e-08, upper_bound=5.960e-08, estim_step=2.980e-08, r = 1.776e+00
    - Step = 2.9802322387695405e-08 is OK: stop.
Computed step = 2.980e-08
Number of iterations = 14
f_prime_approx = 2.7182818800210953
f_prime_exact = 2.718281828459045
</pre></div>
</div>
</section>
<section id="use-the-method-on-the-scaledexponentialproblem">
<h2>Use the method on the ScaledExponentialProblem<a class="headerlink" href="#use-the-method-on-the-scaledexponentialproblem" title="Link to this heading">¶</a></h2>
<p>Consider this problem.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">problem</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">ScaledExponentialProblem</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">problem</span><span class="p">)</span>
<span class="n">name</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_name</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span>
<span class="n">second_derivative</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_second_derivative</span><span class="p">()</span>
<span class="n">second_derivative_value</span> <span class="o">=</span> <span class="n">second_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">optimum_step</span><span class="p">,</span> <span class="n">absolute_error</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">FirstDerivativeForward</span><span class="o">.</span><span class="n">compute_step</span><span class="p">(</span>
    <span class="n">second_derivative_value</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Name = </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">, x = </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimal step for forward finite difference formula = </span><span class="si">{</span><span class="n">optimum_step</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Minimum absolute error= </span><span class="si">{</span><span class="n">absolute_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>DerivativeBenchmarkProblem
name = scaled exp
x = 1.0
f(x) = 0.9999990000005
f&#39;(x) = -9.999990000004999e-07
f&#39;&#39;(x) = 9.999990000005e-13
f^(3)(x) = -9.999990000005e-19
f^(4)(x) = 9.999990000004998e-25
f^(5)(x) = -9.999990000004998e-31

Name = scaled exp, x = 1.0
Optimal step for forward finite difference formula = 0.0200000100000025
Minimum absolute error= 1.99999900000025e-14
</pre></div>
</div>
</section>
<section id="plot-the-error-vs-h">
<h2>Plot the error vs h<a class="headerlink" href="#plot-the-error-vs-h" title="Link to this heading">¶</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">function</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_function</span><span class="p">()</span>
<span class="n">first_derivative</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_first_derivative</span><span class="p">()</span>
<span class="n">finite_difference</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">FirstDerivativeForward</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">number_of_points</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">step_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mf">8.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="n">number_of_points</span><span class="p">)</span>
<span class="n">error_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">number_of_points</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_points</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">step_array</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">f_prime_approx</span> <span class="o">=</span> <span class="n">finite_difference</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
    <span class="n">error_array</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">f_prime_approx</span> <span class="o">-</span> <span class="n">first_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">pl</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">pl</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">step_array</span><span class="p">,</span> <span class="n">error_array</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">optimum_step</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">error_array</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">error_array</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$h^*$&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Forward finite difference&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;h&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Error&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">pl</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_shi_xie_xuan_nocedal_forward_001.png" srcset="../_images/sphx_glr_plot_shi_xie_xuan_nocedal_forward_001.png" alt="Forward finite difference" class = "sphx-glr-single-img"/><p>Use the algorithm to detect h*</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">algorithm</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">ShiXieXuanNocedalForward</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="mf">1.0e0</span>
<span class="n">initial_step</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">h_optimal</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">find_step</span><span class="p">(</span><span class="n">initial_step</span><span class="p">)</span>
<span class="n">number_of_function_evaluations</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">get_number_of_function_evaluations</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimum h =&quot;</span><span class="p">,</span> <span class="n">h_optimal</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;iterations =&quot;</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Function evaluations =&quot;</span><span class="p">,</span> <span class="n">number_of_function_evaluations</span><span class="p">)</span>
<span class="n">f_prime_approx</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">compute_first_derivative</span><span class="p">(</span><span class="n">h_optimal</span><span class="p">)</span>
<span class="n">absolute_error</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">f_prime_approx</span> <span class="o">-</span> <span class="n">problem</span><span class="o">.</span><span class="n">first_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error = &quot;</span><span class="p">,</span> <span class="n">absolute_error</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>x = 1.0
f(x) = 0.9999990000005
f(x + h) = 0.999998000002
f(x + 4 * h) = 0.9999950000125
absolute_precision = 1.000e-15
estim_step=1.000e+00
+ Iter.=0, lower_bound=0.000e+00, upper_bound=inf, estim_step=1.000e+00, r = 7.500e+02
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=1, lower_bound=0.000e+00, upper_bound=1.000e+00, estim_step=2.500e-01, r = 4.691e+01
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=2, lower_bound=0.000e+00, upper_bound=2.500e-01, estim_step=6.250e-02, r = 2.942e+00
    - Step = 0.0625 is OK: stop.
Optimum h = 0.0625
iterations = 2
Function evaluations = 5
Error =  3.1035867193208197e-14
</pre></div>
</div>
</section>
<section id="plot-the-criterion-depending-on-the-step">
<h2>Plot the criterion depending on the step<a class="headerlink" href="#plot-the-criterion-depending-on-the-step" title="Link to this heading">¶</a></h2>
<p>Plot the test ratio depending on h</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">problem</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">ScaledExponentialProblem</span><span class="p">()</span>
<span class="n">function</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_function</span><span class="p">()</span>
<span class="n">name</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_name</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span>
<span class="n">algorithm</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">ShiXieXuanNocedalForward</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">minimum_test_ratio</span><span class="p">,</span> <span class="n">maximum_test_ratio</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">get_ratio_min_max</span><span class="p">()</span>
<span class="n">absolute_precision</span> <span class="o">=</span> <span class="mf">1.0e-15</span>
<span class="n">number_of_points</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">step_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">number_of_points</span><span class="p">)</span>
<span class="n">test_ratio_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">number_of_points</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_points</span><span class="p">):</span>
    <span class="n">test_ratio_array</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">compute_test_ratio</span><span class="p">(</span>
        <span class="n">step_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
    <span class="p">)</span>
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">pl</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">pl</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">step_array</span><span class="p">,</span> <span class="n">test_ratio_array</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test ratio&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">step_array</span><span class="p">,</span> <span class="p">[</span><span class="n">minimum_test_ratio</span><span class="p">]</span> <span class="o">*</span> <span class="n">number_of_points</span><span class="p">,</span> <span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Min&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">step_array</span><span class="p">,</span> <span class="p">[</span><span class="n">maximum_test_ratio</span><span class="p">]</span> <span class="o">*</span> <span class="n">number_of_points</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Max&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> at x = </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">. Test ratio.&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;h&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$r$&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pl</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_shi_xie_xuan_nocedal_forward_002.png" srcset="../_images/sphx_glr_plot_shi_xie_xuan_nocedal_forward_002.png" alt="scaled exp at x = 1.0. Test ratio." class = "sphx-glr-single-img"/></section>
<section id="see-the-history-of-steps-during-the-search">
<h2>See the history of steps during the search<a class="headerlink" href="#see-the-history-of-steps-during-the-search" title="Link to this heading">¶</a></h2>
<p>In Shi, Xie, Xuan &amp; Nocedal's method, the algorithm
produces a sequence of steps <span class="math notranslate nohighlight">\((h_i)_{1 \leq i \leq n_{iter}}\)</span>
where <span class="math notranslate nohighlight">\(n_{iter} \in \mathbb{N}\)</span> is the number of iterations.
These steps are meant to converge to an
approximately optimal step of for the forward finite difference formula of the
first derivative.
The optimal step <span class="math notranslate nohighlight">\(h^\star\)</span> for the central finite difference formula of the
first derivative can be computed depending on the second derivative of the
function.
In the next example, we want to compute the absolute error between
each intermediate step <span class="math notranslate nohighlight">\(h_i\)</span> and the exact value <span class="math notranslate nohighlight">\(h^\star\)</span>
to see how close the algorithm gets to the exact step.
The list of intermediate steps during the algorithm can be obtained
thanks to the <a class="reference internal" href="../user_manual/_generated/numericalderivative.ShiXieXuanNocedalForward.html#numericalderivative.ShiXieXuanNocedalForward.get_step_history" title="numericalderivative.ShiXieXuanNocedalForward.get_step_history"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get_step_history()</span></code></a> method.</p>
<p>In the next example, we print the intermediate steps k during
the bissection algorithm that searches for a step such
that the L ratio is satisfactory.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">problem</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">ScaledExponentialProblem</span><span class="p">()</span>
<span class="n">function</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_function</span><span class="p">()</span>
<span class="n">name</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_name</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span>
<span class="n">algorithm</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">ShiXieXuanNocedalForward</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">initial_step</span> <span class="o">=</span> <span class="mf">1.0e5</span>
<span class="n">step</span><span class="p">,</span> <span class="n">number_of_iterations</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">find_step</span><span class="p">(</span><span class="n">initial_step</span><span class="p">)</span>
<span class="n">step_h_history</span> <span class="o">=</span> <span class="n">algorithm</span><span class="o">.</span><span class="n">get_step_history</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of iterations = </span><span class="si">{</span><span class="n">number_of_iterations</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;History of steps h : </span><span class="si">{</span><span class="n">step_h_history</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">last_step_h</span> <span class="o">=</span> <span class="n">step_h_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Last step h : </span><span class="si">{</span><span class="n">last_step_h</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>x = 1.0
f(x) = 0.9999990000005
f(x + h) = 0.9048365131989939
f(x + 4 * h) = 0.6703193757159285
absolute_precision = 1.000e-15
estim_step=1.000e+05
+ Iter.=0, lower_bound=0.000e+00, upper_bound=inf, estim_step=1.000e+05, r = 6.371e+12
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=1, lower_bound=0.000e+00, upper_bound=1.000e+05, estim_step=2.500e+04, r = 4.497e+11
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=2, lower_bound=0.000e+00, upper_bound=2.500e+04, estim_step=6.250e+03, r = 2.899e+10
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=3, lower_bound=0.000e+00, upper_bound=6.250e+03, estim_step=1.562e+03, r = 1.826e+09
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=4, lower_bound=0.000e+00, upper_bound=1.562e+03, estim_step=3.906e+02, r = 1.144e+08
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=5, lower_bound=0.000e+00, upper_bound=3.906e+02, estim_step=9.766e+01, r = 7.151e+06
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=6, lower_bound=0.000e+00, upper_bound=9.766e+01, estim_step=2.441e+01, r = 4.470e+05
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=7, lower_bound=0.000e+00, upper_bound=2.441e+01, estim_step=6.104e+00, r = 2.794e+04
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=8, lower_bound=0.000e+00, upper_bound=6.104e+00, estim_step=1.526e+00, r = 1.746e+03
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=9, lower_bound=0.000e+00, upper_bound=1.526e+00, estim_step=3.815e-01, r = 1.092e+02
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=10, lower_bound=0.000e+00, upper_bound=3.815e-01, estim_step=9.537e-02, r = 6.828e+00
    - test_ratio &gt; self.minimum_test_ratio. Set upper bound to h.
    - lower_bound == 0: decrease h.
+ Iter.=11, lower_bound=0.000e+00, upper_bound=9.537e-02, estim_step=2.384e-02, r = 4.996e-01
    - test_ratio &lt; self.minimum_test_ratio. Set lower bound to h.
    - Bisection: estim_step = 4.768e-02.
+ Iter.=12, lower_bound=2.384e-02, upper_bound=9.537e-02, estim_step=4.768e-02, r = 1.721e+00
    - Step = 0.04768371582031251 is OK: stop.
Number of iterations = 12
History of steps h : [100000.0, 25000.0, 6250.0, 1562.5, 390.625, 97.65625, 24.4140625, 6.103515625, 1.52587890625, 0.3814697265625, 0.095367431640625, 0.02384185791015625, np.float64(0.04768371582031251)]
Last step h : 0.04768371582031251
</pre></div>
</div>
<p>Then we compute the exact step, using <a class="reference internal" href="../user_manual/_generated/numericalderivative.FirstDerivativeForward.html#numericalderivative.FirstDerivativeForward.compute_step" title="numericalderivative.FirstDerivativeForward.compute_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">compute_step()</span></code></a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">second_derivative</span> <span class="o">=</span> <span class="n">problem</span><span class="o">.</span><span class="n">get_second_derivative</span><span class="p">()</span>
<span class="n">second_derivative_value</span> <span class="o">=</span> <span class="n">second_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;f^(2)(x) = </span><span class="si">{</span><span class="n">second_derivative_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">absolute_precision</span> <span class="o">=</span> <span class="mf">1.0e-16</span>
<span class="n">exact_step</span><span class="p">,</span> <span class="n">absolute_error</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">FirstDerivativeForward</span><span class="o">.</span><span class="n">compute_step</span><span class="p">(</span>
    <span class="n">second_derivative_value</span><span class="p">,</span> <span class="n">absolute_precision</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimal step k for f&#39;(x) using forward F.D. = </span><span class="si">{</span><span class="n">exact_step</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>f^(2)(x) = 9.999990000005e-13
Optimal step k for f&#39;(x) using forward F.D. = 0.0200000100000025
</pre></div>
</div>
<p>Plot the absolute error between the exact step k and the intermediate k
of the algorithm.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">error_step_h</span> <span class="o">=</span> <span class="p">[</span><span class="nb">abs</span><span class="p">(</span><span class="n">step_h_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">exact_step</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">step_h_history</span><span class="p">))]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">))</span>
<span class="n">pl</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shi, Xie, Xuan &amp; Nocedal on </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> at x = </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">step_h_history</span><span class="p">)),</span> <span class="n">error_step_h</span><span class="p">,</span> <span class="s2">&quot;o-&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iterations&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$|h_i - h^\star|$&quot;</span><span class="p">)</span>
<span class="n">pl</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_locator</span><span class="p">(</span><span class="n">MaxNLocator</span><span class="p">(</span><span class="n">integer</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">pl</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_shi_xie_xuan_nocedal_forward_003.png" srcset="../_images/sphx_glr_plot_shi_xie_xuan_nocedal_forward_003.png" alt="Shi, Xie, Xuan & Nocedal on scaled exp at x = 1.0" class = "sphx-glr-single-img"/><p>The previous figure shows that the algorithm converges relatively fast.
The absolute error does not evolve monotically.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 0.676 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-example-plot-shi-xie-xuan-nocedal-forward-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/ac792e23258bcb8759c99de938bb2407/plot_shi_xie_xuan_nocedal_forward.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_shi_xie_xuan_nocedal_forward.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/7fa414a7807cea92565df4329df96033/plot_shi_xie_xuan_nocedal_forward.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_shi_xie_xuan_nocedal_forward.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/58a510c5a258d26b08a963c5543dfc86/plot_shi_xie_xuan_nocedal_forward.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_shi_xie_xuan_nocedal_forward.zip</span></code></a></p>
</div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">numericalderivative</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../user_manual/user_manual.html">User manual</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../examples/examples.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="plot_numericalderivative.html">A simple demonstration of the methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_openturns.html">Applies Stepleman &amp; Winarsky method to an OpenTURNS function</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_use_benchmark.html">Use the benchmark problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_finite_differences.html">Use the finite differences formulas</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_general_fd.html">Use the generalized finite differences formulas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/examples.html#dumontet-vignes">Dumontet &amp; Vignes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/examples.html#gill-murray-saunders-wright">Gill, Murray, Saunders &amp; Wright</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/examples.html#stepleman-winarsky">Stepleman &amp; Winarsky</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../examples/examples.html#shi-xie-xuan-nocedal">Shi, Xie, Xuan &amp; Nocedal</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Experiment with Shi, Xie, Xuan &amp; Nocedal forward method</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_shi_xie_xuan_nocedal_forward_benchmark.html">Benchmark Shi, Xie, Xuan &amp; Nocedal's forward method</a></li>
</ul>
</li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="../examples/examples.html">Examples</a><ul>
      <li>Previous: <a href="plot_stepleman_winarsky_benchmark.html" title="previous chapter">Benchmark Stepleman &amp; Winarsky's method</a></li>
      <li>Next: <a href="plot_shi_xie_xuan_nocedal_forward_benchmark.html" title="next chapter">Benchmark Shi, Xie, Xuan &amp; Nocedal's forward method</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;M. Baudin.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="../_sources/auto_example/plot_shi_xie_xuan_nocedal_forward.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>