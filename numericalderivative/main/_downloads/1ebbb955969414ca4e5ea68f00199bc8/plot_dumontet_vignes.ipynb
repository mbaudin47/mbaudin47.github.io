{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Experiments with Dumontet & Vignes method\n\n## References\n- Dumontet, J., & Vignes, J. (1977). D\u00e9termination du pas optimal dans le calcul des d\u00e9riv\u00e9es sur ordinateur. RAIRO. Analyse num\u00e9rique, 11 (1), 13-25.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pylab as pl\nimport numericalderivative as nd\nimport sys\nfrom matplotlib.ticker import MaxNLocator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use the method on a simple problem\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next example, we use the algorithm on the exponential function.\nWe create the :class:`~numericalderivative.DumontetVignes` algorithm using the function and the point x.\nThen we use the :meth:`~numericalderivative.DumontetVignes.compute_step()` method to compute the step,\nusing an upper bound of the step as an initial point of the algorithm.\nFinally, use the :meth:`~numericalderivative.DumontetVignes.compute_first_derivative()` method to compute\nan approximate value of the first derivative using finite differences.\nThe :meth:`~numericalderivative.DumontetVignes.get_number_of_function_evaluations()` method\ncan be used to get the number of function evaluations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 1.0\nkmin = 1.0e-10\nkmax = 1.0e0\nalgorithm = nd.DumontetVignes(np.exp, x, verbose=True)\nstep, number_of_iterations = algorithm.compute_step(kmin=kmin, kmax=kmax)\nf_prime_approx = algorithm.compute_first_derivative(step)\nfeval = algorithm.get_number_of_function_evaluations()\nf_prime_exact = np.exp(x)  # Since the derivative of exp is exp.\nprint(f\"Computed step = {step:.3e}\")\nprint(f\"Number of iterations = {number_of_iterations}\")\nprint(f\"f_prime_approx = {f_prime_approx}\")\nprint(f\"f_prime_exact = {f_prime_exact}\")\nabsolute_error = abs(f_prime_approx - f_prime_exact)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Useful functions\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These functions will be used later in this example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_ell(function, x, k, relative_precision):\n    \"\"\"\n    Compute the L ratio for a given value of the step k.\n    \"\"\"\n    algorithm = nd.DumontetVignes(function, x, relative_precision=relative_precision)\n    ell = algorithm.compute_ell(k)\n    return ell\n\n\ndef compute_f3_inf_sup(function, x, k, relative_precision):\n    \"\"\"\n    Compute the upper and lower bounds of the third derivative for a given value of k.\n    \"\"\"\n    algorithm = nd.DumontetVignes(function, x, relative_precision=relative_precision)\n    _, f3inf, f3sup = algorithm.compute_ell(k)\n    return f3inf, f3sup\n\n\ndef plot_step_sensitivity(\n    x,\n    name,\n    function,\n    function_derivative,\n    function_third_derivative,\n    step_array,\n    iteration_maximum=53,\n    relative_precision=1.0e-15,\n    kmin=None,\n    kmax=None,\n):\n    \"\"\"\n    Create a plot representing the absolute error depending on step.\n\n    Compute the approximate derivative using central F.D. formula.\n    Plot the approximately optimal step computed by DumontetVignes.\n\n    Parameters\n    ----------\n    x : float\n        The input point\n    name : str\n        The name of the problem\n    function : function\n        The function.\n    function_derivative : function\n        The exact first derivative of the function.\n    function_third_derivative : function\n        The exact third derivative of the function.\n    step_array : array(n_points)\n        The array of steps to consider\n    iteration_maximum : int\n        The maximum number of iterations in DumontetVignes\n    relative_precision : float, > 0\n        The relative precision of the function evaluation\n    kmin : float, kmin > 0\n        A minimum bound for k. The default is None.\n        If no value is provided, the default is to compute the smallest\n        possible kmin using number_of_digits and x.\n    kmax : float, kmax > kmin > 0\n        A maximum bound for k. The default is None.\n        If no value is provided, the default is to compute the largest\n        possible kmax using number_of_digits and x.\n    \"\"\"\n    print(\"+ \", name)\n    # 1. Plot the error vs h\n    algorithm = nd.DumontetVignes(function, x, verbose=True)\n    number_of_points = len(step_array)\n    error_array = np.zeros((number_of_points))\n    for i in range(number_of_points):\n        f_prime_approx = algorithm.compute_first_derivative(step_array[i])\n        error_array[i] = abs(f_prime_approx - function_derivative(x))\n\n    # 2. Algorithm to detect h*\n    algorithm = nd.DumontetVignes(function, x, relative_precision=relative_precision)\n    print(\"Exact f'''(x) = %.3e\" % (function_third_derivative(x)))\n    estim_step, _ = algorithm.compute_step(\n        iteration_maximum=iteration_maximum,\n        markdown=False,\n        kmin=kmin,\n        kmax=kmax,\n    )\n    fprime = algorithm.compute_first_derivative(estim_step)\n    number_of_function_evaluations = algorithm.get_number_of_function_evaluations()\n    print(\"Function evaluations =\", number_of_function_evaluations)\n    print(\"Estim. derivative = %.3e\" % (fprime))\n    print(\"Exact. derivative = %.3e\" % (function_derivative(x)))\n    f_prime_approx = algorithm.compute_first_derivative(estim_step)\n    absolute_error = abs(f_prime_approx - function_derivative(x))\n    print(\"Exact abs. error  = %.3e\" % (absolute_error))\n    print(\"Exact rel. error  = %.3e\" % (absolute_error / abs(function_derivative(x))))\n    # Compute exact step\n    absolute_precision = abs(function(x) * relative_precision)\n    third_derivative_value = function_third_derivative(x)\n    optimal_step, optimal_error = nd.FirstDerivativeCentral.compute_step(\n        third_derivative_value, absolute_precision\n    )\n    print(\"Exact step     = %.3e\" % (optimal_step))\n    print(\"Estimated step = %.3e\" % (estim_step))\n    print(\"Optimal abs. error = %.3e\" % (optimal_error))\n    print(\"Optimal rel. error = %.3e\" % (optimal_error / abs(function_derivative(x))))\n\n    minimum_error = np.nanmin(error_array)\n    maximum_error = np.nanmax(error_array)\n\n    pl.figure()\n    pl.plot(step_array, error_array)\n    pl.plot(\n        [estim_step] * 2, [minimum_error, maximum_error], \"--\", label=r\"$\\widetilde{h}$\"\n    )\n    pl.plot(optimal_step, optimal_error, \"o\", label=r\"$h^\\star$\")\n    pl.title(\"Finite difference for %s\" % (name))\n    pl.xlabel(\"h\")\n    pl.ylabel(\"Error\")\n    pl.xscale(\"log\")\n    pl.yscale(\"log\")\n    pl.legend(bbox_to_anchor=(1.1, 1.0))\n    pl.tight_layout()\n    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_ell_ratio(\n    name,\n    function,\n    x,\n    number_of_points,\n    number_of_digits,\n    relative_precision,\n    kmin=None,\n    kmax=None,\n    y_logscale=False,\n    plot_L_constants=False,\n):\n    \"\"\"Plot the ell ratio depending on the step size.\n\n    This ell ratio is used in DumontetVignes.\"\"\"\n    ell_1 = 1.0 / 15.0  # Eq. 34, fixed\n    ell_2 = 1.0 / 2.0\n    ell_3 = 1.0 / ell_2\n    ell_4 = 1.0 / ell_1\n\n    if kmin is None:\n        print(\"Set default kmin\")\n        kmin = x * 2 ** (-number_of_digits + 1)  # Eq. 26\n    if kmax is None:\n        print(\"Set default kmax\")\n        kmax = x * 2 ** (number_of_digits - 1)\n    k_array = np.logspace(np.log10(kmin), np.log10(kmax), number_of_points)\n    ell_array = np.zeros((number_of_points))\n    for i in range(number_of_points):\n        ell_array[i], _, _ = compute_ell(function, x, k_array[i], relative_precision)\n\n    pl.figure()\n    pl.plot(k_array, ell_array, label=\"L\")\n    if plot_L_constants:\n        indices = np.isfinite(ell_array)\n        maximum_finite_ell = np.max(ell_array[indices])\n        print(\"Maximum L = %.3e\" % (maximum_finite_ell))\n        if maximum_finite_ell < 1.0:\n            pl.plot(k_array, [ell_1] * number_of_points, \"--\", label=\"$L_1$\")\n            pl.plot(k_array, [ell_2] * number_of_points, \":\", label=\"$L_2$\")\n        else:\n            pl.plot(k_array, [ell_3] * number_of_points, \":\", label=\"$L_3$\")\n            pl.plot(k_array, [ell_4] * number_of_points, \"--\", label=\"$L_4$\")\n        pl.legend(bbox_to_anchor=(1.0, 1.0))\n    pl.title(f\"{name}, x = {x:.2e}, p = {relative_precision:.2e}\")\n    pl.xlabel(\"k\")\n    pl.ylabel(\"L\")\n    pl.xscale(\"log\")\n    if y_logscale:\n        pl.yscale(\"log\")\n    #\n    pl.tight_layout()\n    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot the L ratio for various problems\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The L ratio is the criterion used in (Dumontet & Vignes, 1977) algorithm\nto find a satisfactory step k.\nThe algorithm searches for a step k so that the L ratio is inside\nan interval.\nThis is computed by the :meth:`~numericalderivative.DumontetVignes.compute_ell`\nmethod.\nIn the next examples, we plot the L ratio depending on k\nfor different functions.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Consider the :class:`~numericalderivative.ExponentialProblem` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_points = 200\nrelative_precision = 1.0e-15\nx = 1.0\nproblem = nd.ExponentialProblem()\nproblem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_digits = 53\nplot_ell_ratio(\n    problem.get_name(),\n    problem.get_function(),\n    x,\n    number_of_points,\n    number_of_digits,\n    relative_precision,\n    kmin=1.55e-5,\n    kmax=1.0e-4,\n    plot_L_constants=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider a larger interval of K.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "relative_precision = 1.0e-10\nx = 1.0\nproblem = nd.ExponentialProblem()\nnumber_of_digits = 53\nplot_ell_ratio(\n    problem.get_name(),\n    problem.get_function(),\n    x,\n    number_of_points,\n    number_of_digits,\n    relative_precision,\n    kmin=5.0e-5,\n    kmax=1.0e-2,\n    y_logscale=False,\n    plot_L_constants=True,\n)\npl.ylim(-20.0, 20.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "See how the figure changes when the relative precision is\ndecreased: use 1.e-14 (instead of 1.e-10 in the previous example).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "relative_precision = 1.0e-14\nx = 1.0\nproblem = nd.ExponentialProblem()\nnumber_of_digits = 53\nplot_ell_ratio(\n    problem.get_name(),\n    problem.get_function(),\n    x,\n    number_of_points,\n    number_of_digits,\n    relative_precision,\n    kmin=4.0e-5,\n    kmax=1.0e-2,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "See what happens at x = 4 (instead of x = 1 in the previous example).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "relative_precision = 1.0e-16\nx = 4.0  # A carefully chosen point\nproblem = nd.ExponentialProblem()\nnumber_of_digits = 53\nplot_ell_ratio(\n    problem.get_name(),\n    problem.get_function(),\n    x,\n    number_of_points,\n    number_of_digits,\n    relative_precision,\n    kmin=1.0e-5,\n    kmax=1.0e-2,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider a larger interval of k.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "relative_precision = 1.0e-14\nx = 4.0  # A carefully chosen point\nproblem = nd.ExponentialProblem()\nnumber_of_digits = 53\nplot_ell_ratio(\n    problem.get_name(),\n    problem.get_function(),\n    x,\n    number_of_points,\n    number_of_digits,\n    relative_precision,\n    kmin=3.2e-5,\n    kmax=1.0e-2,\n    y_logscale=False,\n    plot_L_constants=True,\n)\npl.ylim(-20.0, 20.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot the error depending on the step\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next examples, we plot the error of the approximation of the\nfirst derivative by the finite difference formula depending\non the step size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 4.0\nproblem = nd.ExponentialProblem()\nfunction = problem.get_function()\nabsolute_precision = sys.float_info.epsilon * function(x)\nprint(\"absolute_precision = %.3e\" % (absolute_precision))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 4.1  # A carefully chosen point\nrelative_precision = sys.float_info.epsilon\nnumber_of_points = 200\nstep_array = np.logspace(-15.0, 0.0, number_of_points)\nkmin = 1.0e-5\nkmax = 1.0e-2\nplot_step_sensitivity(\n    x,\n    problem.get_name(),\n    problem.get_function(),\n    problem.get_first_derivative(),\n    problem.get_third_derivative(),\n    step_array,\n    iteration_maximum=20,\n    relative_precision=1.0e-15,\n    kmin=kmin,\n    kmax=kmax,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the previous figure, we see that the error reaches\na minimum, which is indicated by the green point labeled $h^\\star$.\nThe vertical dotted line represents the approximately optimal step $\\widetilde{h}$\nreturned by the :meth:`~numericalderivative.DumontetVignes.compute_step` method.\nWe see that the method correctly computes an approximation of the the optimal step.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider the :class:`~numericalderivative.ScaledExponentialProblem`.\nFirst, we plot the L ratio.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "relative_precision = 1.0e-14\nproblem = nd.ScaledExponentialProblem()\nnumber_of_digits = 53\nplot_ell_ratio(\n    problem.get_name(),\n    problem.get_function(),\n    problem.get_x(),\n    number_of_points,\n    number_of_digits,\n    relative_precision,\n    kmin=1.0e-1,\n    kmax=1.0e2,\n    plot_L_constants=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then plot the error depending on the step size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "problem = nd.ScaledExponentialProblem()\nstep_array = np.logspace(-7.0, 6.0, number_of_points)\nplot_step_sensitivity(\n    problem.get_x(),\n    problem.get_name(),\n    problem.get_function(),\n    problem.get_first_derivative(),\n    problem.get_third_derivative(),\n    step_array,\n    relative_precision=1.0e-15,\n    kmin=1.0e-2,\n    kmax=1.0e2,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previous figure shows that the optimal step is close to\n$10^1$, which may be larger than what we may typically expect\nas a step size for a finite difference formula.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider the :class:`~numericalderivative.SquareRootProblem`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "relative_precision = 1.0e-14\nproblem = nd.SquareRootProblem()\nnumber_of_digits = 53\nplot_ell_ratio(\n    problem.get_name(),\n    problem.get_function(),\n    problem.get_x(),\n    number_of_points,\n    number_of_digits,\n    relative_precision,\n    kmin=4.3e-5,\n    kmax=1.0e-4,\n    plot_L_constants=True,\n)\npl.ylim(-20.0, 20.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute the lower and upper bounds of the third derivative\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The algorithm is based on bounds of the third derivative, which is\ncomputed by the :meth:`~numericalderivative.DumontetVignes.compute_ell` method.\nThese bounds are used to find a step which is approximately\noptimal to compute the step of the finite difference formula\nused for the first derivative.\nHence, it is interesting to compare the bounds computed\nby the (Dumontet & Vignes, 1977) algorithm and the\nactual value of the third derivative.\nTo compute the true value of the third derivative,\nwe use two different methods:\n\n- a finite difference formula, using :class:`~numericalderivative.ThirdDerivativeCentral`,\n- the exact third derivative, using :meth:`~numericalderivative.SquareRootProblem.get_third_derivative`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 1.0\nk = 1.0e-3  # A first guess\nprint(\"x = \", x)\nprint(\"k = \", k)\nproblem = nd.SquareRootProblem()\nfunction = problem.get_function()\nfinite_difference = nd.ThirdDerivativeCentral(function, x)\napprox_f3d = finite_difference.compute(k)\nprint(\"Approx. f''(x) = \", approx_f3d)\nthird_derivative = problem.get_third_derivative()\nexact_f3d = third_derivative(x)\nprint(\"Exact f''(x) = \", exact_f3d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "relative_precision = 1.0e-14\nprint(\"relative_precision = \", relative_precision)\nfunction = problem.get_function()\nf3inf, f3sup = compute_f3_inf_sup(function, x, k, relative_precision)\nprint(\"f3inf = \", f3inf)\nprint(\"f3sup = \", f3sup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previous outputs shows that the lower and upper bounds\ncomputed by the algorithm contain, indeed, the true value of the\nthird derivative in this case.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The algorithm is based on finding an approximatly optimal\nstep k to compute the third derivative.\nThe next script computes the error of the central formula for the\nfinite difference formula depending on the step k.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_points = 200\nfunction = problem.get_function()\nthird_derivative = problem.get_third_derivative()\nk_array = np.logspace(-6.0, -1.0, number_of_points)\nerror_array = np.zeros((number_of_points))\nalgorithm = nd.ThirdDerivativeCentral(function, x)\nfor i in range(number_of_points):\n    f2nde_approx = algorithm.compute(k_array[i])\n    error_array[i] = abs(f2nde_approx - third_derivative(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pl.figure()\npl.plot(k_array, error_array)\npl.title(\"F. D. of 3de derivative for %s\" % (problem.get_name()))\npl.xlabel(\"k\")\npl.ylabel(\"Error\")\npl.xscale(\"log\")\npl.yscale(\"log\")\n#\npl.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot the lower and upper bounds of the third derivative\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next figure presents the sensitivity of the\nlower and upper bounds of the third derivative to the step k.\nMoreover, it presents the approximation of the third derivative\nusing the central finite difference formula.\nThis makes it possible to check that the lower and upper bounds\nactually contain the approximation produced by the F.D. formula.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "problem = nd.SquareRootProblem()\nnumber_of_points = 200\nrelative_precision = 1.0e-16\nk_array = np.logspace(-5.0, -4.0, number_of_points)\nf3_array = np.zeros((number_of_points, 3))\nfunction = problem.get_function()\nalgorithm = nd.ThirdDerivativeCentral(function, x)\nfor i in range(number_of_points):\n    f3inf, f3sup = compute_f3_inf_sup(function, x, k_array[i], relative_precision)\n    f3_approx = algorithm.compute(k_array[i])\n    f3_array[i] = [f3inf, f3_approx, f3sup]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pl.figure()\npl.plot(k_array, f3_array[:, 0], \":\", label=\"f3inf\")\npl.plot(k_array, f3_array[:, 1], \"-\", label=\"$D^{(3)}_f$\")\npl.plot(k_array, f3_array[:, 2], \":\", label=\"f3sup\")\npl.title(f\"F.D. of 3de derivative for {problem.get_name()} at x = {x}\")\npl.xlabel(\"k\")\npl.xscale(\"log\")\npl.legend(bbox_to_anchor=(1.0, 1.0))\npl.tight_layout(pad=1.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 1.0e-2\nrelative_precision = 1.0e-14\nnumber_of_digits = 53\nplot_ell_ratio(\n    problem.get_name(),\n    problem.get_function(),\n    x,\n    number_of_points,\n    number_of_digits,\n    relative_precision,\n    kmin=4.4e-7,\n    kmax=1.0e-5,\n    plot_L_constants=True,\n)\npl.ylim(-20.0, 20.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next example searches the optimal step for the square root function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 1.0e-2\nrelative_precision = 1.0e-14\nkmin = 1.0e-8\nkmax = 1.0e-3\nverbose = True\nfunction = problem.get_function()\nalgorithm = nd.DumontetVignes(\n    function, x, relative_precision=relative_precision, verbose=verbose\n)\nh_optimal, _ = algorithm.compute_step(kmax=kmax)\nprint(\"h optimal = %.3e\" % (h_optimal))\nnumber_of_feval = algorithm.get_number_of_function_evaluations()\nprint(f\"number_of_feval = {number_of_feval}\")\nf_prime_approx = algorithm.compute_first_derivative(h_optimal)\nfeval = algorithm.get_number_of_function_evaluations()\nfirst_derivative = problem.get_first_derivative()\nabsolute_error = abs(f_prime_approx - first_derivative(x))\nprint(\"Abs. error = %.3e\" % (absolute_error))\n\nell_kmin, f3inf, f3sup = algorithm.compute_ell(kmin)\nprint(\"L(kmin) = \", ell_kmin)\nell_kmax, f3inf, f3sup = algorithm.compute_ell(kmax)\nprint(\"L(kmax) = \", ell_kmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider the :class:`~numericalderivative.SinProblem`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 1.0\nrelative_precision = 1.0e-14\nproblem = nd.SinProblem()\nfunction = problem.get_function()\nname = \"sin\"\nnumber_of_digits = 53\nkmin = 1.0e-5\nkmax = 1.0e-3\nplot_ell_ratio(\n    name,\n    function,\n    x,\n    number_of_points,\n    number_of_digits,\n    relative_precision,\n    kmin=kmin,\n    kmax=kmax,\n    plot_L_constants=True,\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = 1.0\nk = 1.0e-3\nprint(\"x = \", x)\nprint(\"k = \", k)\nfunction = problem.get_function()\nalgorithm = nd.ThirdDerivativeCentral(function, x)\napprox_f3d = algorithm.compute(k)\nprint(\"Approx. f''(x) = \", approx_f3d)\nthird_derivative = problem.get_third_derivative()\nexact_f3d = third_derivative(x)\nprint(\"Exact f''(x) = \", exact_f3d)\nrelative_precision = 1.0e-14\nprint(\"relative_precision = \", relative_precision)\nfunction = problem.get_function()\nf3inf, f3sup = compute_f3_inf_sup(function, x, k, relative_precision)\nprint(\"f3inf = \", f3inf)\nprint(\"f3sup = \", f3sup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## See the history of steps during the bissection search\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In Dumontet & Vignes's method, the bisection algorithm\nproduces a sequence of steps $(k_i)_{1 \\leq i \\leq n_{iter}}$\nwhere $n_{iter} \\in \\mathbb{N}$ is the number of iterations.\nThese steps are meant to converge to an\napproximately optimal step of for the central finite difference formula of the\nthird derivative.\nThe optimal step $k^\\star$ for the central finite difference formula of the\nthird derivative can be computed depending on the fifth derivative of the\nfunction.\nIn the next example, we want to compute the absolute error between\neach intermediate step $k_i$ and the exact value $k^\\star$\nto see how close the algorithm gets to the exact step.\nThe list of intermediate steps during the algorithm can be obtained\nthanks to the :meth:`~numericalderivative.DumontetVignes.get_step_history` method.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next example, we print the intermediate steps k during\nthe bissection algorithm that searches for a step such\nthat the L ratio is satisfactory.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "problem = nd.SinProblem()\nfunction = problem.get_function()\nname = problem.get_name()\nx = problem.get_x()\nalgorithm = nd.DumontetVignes(function, x, verbose=True)\nkmin = 1.0e-10\nkmax = 1.0e0\nstep, number_of_iterations = algorithm.compute_step(kmin=kmin, kmax=kmax)\nstep_k_history = algorithm.get_step_history()\nprint(f\"Number of iterations = {number_of_iterations}\")\nprint(f\"History of steps k : {step_k_history}\")\nlast_step_k = step_k_history[-1]\nprint(f\"Last step k : {last_step_k}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we compute the exact step, using :meth:`~numericalderivative.ThirdDerivativeCentral.compute_step`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fifth_derivative = problem.get_fifth_derivative()\nfifth_derivative_value = fifth_derivative(x)\nprint(f\"f^(5)(x) = {fifth_derivative_value}\")\nabsolute_precision = 1.0e-16\nexact_step_k, absolute_error = nd.ThirdDerivativeCentral.compute_step(\n    fifth_derivative_value, absolute_precision\n)\nprint(f\"Optimal step k for f^(3)(x) = {exact_step_k}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the absolute error between the exact step k and the intermediate k\nof the algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "error_step_k = [\n    abs(step_k_history[i] - exact_step_k) for i in range(len(step_k_history))\n]\nfig = pl.figure()\npl.title(f\"Dumontet & Vignes on {name} at x = {x}\")\npl.plot(range(len(step_k_history)), error_step_k, \"o-\")\npl.xlabel(\"Iterations\")\npl.ylabel(r\"$|k_i - k^\\star|$\")\npl.yscale(\"log\")\nax = fig.gca()\nax.xaxis.set_major_locator(MaxNLocator(integer=True))\npl.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The previous figure shows that the algorithm gets closer to the optimal\nvalue of the step k in the early iterations.\nIn the last iterations of the algorithm, the absolute error does not\ncontinue to decrease monotically and produces a final absolute\nerror close to $10^{-3}$.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}