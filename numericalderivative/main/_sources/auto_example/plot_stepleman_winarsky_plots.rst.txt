
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_example/plot_stepleman_winarsky_plots.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_example_plot_stepleman_winarsky_plots.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_example_plot_stepleman_winarsky_plots.py:


Plot Stepleman & Winarsky's method
==================================

Find a step which is near to optimal for a centered finite difference 
formula.

References
----------
- Adaptive numerical differentiation
  R. S. Stepleman and N. D. Winarsky
  Journal: Math. Comp. 33 (1979), 1257-1264 

.. GENERATED FROM PYTHON SOURCE LINES 19-25

.. code-block:: Python

    import numpy as np
    import pylab as pl
    import tabulate
    import numericalderivative as nd









.. GENERATED FROM PYTHON SOURCE LINES 26-27

Plot the number of lost digits for exp

.. GENERATED FROM PYTHON SOURCE LINES 27-43

.. code-block:: Python

    number_of_points = 100
    x = 1.0
    h_array = np.logspace(-15.0, 1.0, number_of_points)
    n_digits_array = np.zeros((number_of_points))
    algorithm = nd.SteplemanWinarsky(np.exp, x)
    for i in range(number_of_points):
        h = h_array[i]
        n_digits_array[i] = algorithm.number_of_lost_digits(h)

    pl.figure()
    pl.plot(h_array, n_digits_array)
    pl.title(r"Number of digits lost by F.D.. $f(x) = \exp(x)$")
    pl.xlabel("h")
    pl.ylabel("$N(h)$")
    pl.xscale("log")




.. image-sg:: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_001.png
   :alt: Number of digits lost by F.D.. $f(x) = \exp(x)$
   :srcset: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 44-45

Plot the number of lost digits for sin

.. GENERATED FROM PYTHON SOURCE LINES 45-53

.. code-block:: Python

    x = 1.0
    h_array = np.logspace(-7.0, 2.0, number_of_points)
    n_digits_array = np.zeros((number_of_points))
    algorithm = nd.SteplemanWinarsky(np.sin, x)
    for i in range(number_of_points):
        h = h_array[i]
        n_digits_array[i] = algorithm.number_of_lost_digits(h)








.. GENERATED FROM PYTHON SOURCE LINES 54-61

.. code-block:: Python

    pl.figure()
    pl.plot(h_array, n_digits_array)
    pl.title(r"Number of digits lost by F.D.. $f(x) = \sin(x)$")
    pl.xlabel("h")
    pl.ylabel("$N(h)$")
    pl.xscale("log")




.. image-sg:: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_002.png
   :alt: Number of digits lost by F.D.. $f(x) = \sin(x)$
   :srcset: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 62-64

For each function, at point x = 1, plot the error vs the step computed
by the method

.. GENERATED FROM PYTHON SOURCE LINES 67-126

.. code-block:: Python

    def plot_error_vs_h_with_SW_steps(
        name, function, function_derivative, x, h_array, h_min, h_max, verbose=False
    ):
        algorithm = nd.SteplemanWinarsky(function, x)
        number_of_points = len(h_array)
        error_array = np.zeros((number_of_points))
        for i in range(number_of_points):
            h = h_array[i]
            f_prime_approx = algorithm.compute_first_derivative(h)
            error_array[i] = abs(f_prime_approx - function_derivative(x))

        bisection_h0_step, bisection_h0_iteration = algorithm.search_step_with_bisection(
            h_min, h_max
        )
        step, bisection_iterations = algorithm.compute_step(bisection_h0_step)

        if verbose:
            print(name)
            print(f"h_min = {h_min:.3e}, h_max = {h_max:.3e}")
            print(
                "Bisection h0 = %.3e using %d iterations"
                % (bisection_h0_step, bisection_h0_iteration)
            )
            print("Bisection h* = %.3e using %d iterations" % (step, bisection_iterations))

        minimum_error = np.nanmin(error_array)
        maximum_error = np.nanmax(error_array)

        pl.figure()
        pl.plot(h_array, error_array)
        pl.plot(
            [h_min] * 2,
            [minimum_error, maximum_error],
            "--",
            label=r"$h_{\min}$",
        )
        pl.plot(
            [h_max] * 2,
            [minimum_error, maximum_error],
            "--",
            label=r"$h_{\max}$",
        )
        pl.plot(
            [bisection_h0_step] * 2,
            [minimum_error, maximum_error],
            "--",
            label="$h_{0}^{(B)}$",
        )
        pl.plot([step] * 2, [minimum_error, maximum_error], "--", label="$h^{*}$")
        pl.title("Finite difference : %s at point x = %.0f" % (name, x))
        pl.xlabel("h")
        pl.ylabel("Error")
        pl.xscale("log")
        pl.yscale("log")
        pl.legend(bbox_to_anchor=(1.0, 1.0))
        pl.subplots_adjust(right=0.8)
        return









.. GENERATED FROM PYTHON SOURCE LINES 127-140

.. code-block:: Python

    def plot_error_vs_h_benchmark(benchmark, x, h_array, h_min, h_max, verbose=False):
        plot_error_vs_h_with_SW_steps(
            benchmark.name,
            benchmark.function,
            benchmark.first_derivative,
            x,
            h_array,
            h_min,
            h_max,
            True,
        )









.. GENERATED FROM PYTHON SOURCE LINES 141-147

.. code-block:: Python

    benchmark = nd.ExponentialProblem()
    x = 1.0
    number_of_points = 1000
    h_array = np.logspace(-15.0, 1.0, number_of_points)
    plot_error_vs_h_benchmark(benchmark, x, h_array, 1.0e-10, 1.0e0, True)




.. image-sg:: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_003.png
   :alt: Finite difference : exp at point x = 1
   :srcset: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    exp
    h_min = 1.000e-10, h_max = 1.000e+00
    Bisection h0 = 1.000e-05 using 0 iterations
    Bisection h* = 2.500e-06 using 1 iterations




.. GENERATED FROM PYTHON SOURCE LINES 148-157

.. code-block:: Python

    x = 12.0
    h_array = np.logspace(-15.0, 1.0, number_of_points)
    plot_error_vs_h_benchmark(benchmark, x, h_array, 1.0e-10, 1.0e0)

    if False:
        benchmark = nd.LogarithmicProblem()
        x = 1.0
        plot_error_vs_h_benchmark(benchmark, x, h_array, 1.0e-15, 1.0e0, True)




.. image-sg:: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_004.png
   :alt: Finite difference : exp at point x = 12
   :srcset: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_004.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    exp
    h_min = 1.000e-10, h_max = 1.000e+00
    Bisection h0 = 1.000e-05 using 0 iterations
    Bisection h* = 2.500e-06 using 1 iterations




.. GENERATED FROM PYTHON SOURCE LINES 158-163

.. code-block:: Python

    benchmark = nd.LogarithmicProblem()
    x = 1.1
    h_array = np.logspace(-15.0, -1.0, number_of_points)
    plot_error_vs_h_benchmark(benchmark, x, h_array, 1.0e-14, 1.0e-1, True)




.. image-sg:: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_005.png
   :alt: Finite difference : log at point x = 1
   :srcset: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_005.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    log
    h_min = 1.000e-14, h_max = 1.000e-01
    Bisection h0 = 5.623e-05 using 1 iterations
    Bisection h* = 8.787e-07 using 3 iterations




.. GENERATED FROM PYTHON SOURCE LINES 164-169

.. code-block:: Python

    benchmark = nd.SinProblem()
    x = 1.0
    h_array = np.logspace(-15.0, 0.0, number_of_points)
    plot_error_vs_h_benchmark(benchmark, x, h_array, 1.0e-15, 1.0e-0)




.. image-sg:: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_006.png
   :alt: Finite difference : sin at point x = 1
   :srcset: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_006.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    sin
    h_min = 1.000e-15, h_max = 1.000e+00
    Bisection h0 = 1.778e-04 using 1 iterations
    Bisection h* = 2.779e-06 using 3 iterations




.. GENERATED FROM PYTHON SOURCE LINES 170-175

.. code-block:: Python

    benchmark = nd.SquareRootProblem()
    x = 1.0
    h_array = np.logspace(-15.0, 0.0, number_of_points)
    plot_error_vs_h_benchmark(benchmark, x, h_array, 1.0e-15, 1.0e-0, True)




.. image-sg:: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_007.png
   :alt: Finite difference : sqrt at point x = 1
   :srcset: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_007.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    sqrt
    h_min = 1.000e-15, h_max = 1.000e+00
    Bisection h0 = 1.778e-04 using 1 iterations
    Bisection h* = 2.779e-06 using 3 iterations




.. GENERATED FROM PYTHON SOURCE LINES 176-181

.. code-block:: Python

    benchmark = nd.AtanProblem()
    x = 1.0
    h_array = np.logspace(-15.0, 0.0, number_of_points)
    plot_error_vs_h_benchmark(benchmark, x, h_array, 1.0e-15, 1.0e-0)




.. image-sg:: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_008.png
   :alt: Finite difference : atan at point x = 1
   :srcset: /auto_example/images/sphx_glr_plot_stepleman_winarsky_plots_008.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    atan
    h_min = 1.000e-15, h_max = 1.000e+00
    Bisection h0 = 1.778e-04 using 1 iterations
    Bisection h* = 2.779e-06 using 3 iterations




.. GENERATED FROM PYTHON SOURCE LINES 182-203

.. code-block:: Python

    benchmark = nd.ExponentialProblem()
    print("+ Sensitivity of SW step depending on h0")
    print("Case 1 : exp")
    x = 1.0
    algorithm = nd.SteplemanWinarsky(
        benchmark.function,
        x,
    )
    third_derivative_value = benchmark.third_derivative(benchmark.x)
    optimal_step, absolute_error = nd.FirstDerivativeCentral.compute_step(
        third_derivative_value
    )
    print("Exact h* = %.3e" % (optimal_step))
    print("absolute_error = %.3e" % (absolute_error))
    for h0 in np.logspace(-4, 0, 10):
        estim_step, iterations = algorithm.compute_step(h0)
        print("h0 = %.3e, Approx. h* = %.3e (%d iterations)" % (h0, estim_step, iterations))

    print("Case 2 : Scaled exp")
    x = 1.0





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    + Sensitivity of SW step depending on h0
    Case 1 : exp
    Exact h* = 4.797e-06
    absolute_error = 3.127e-11
    h0 = 1.000e-04, Approx. h* = 1.563e-06 (3 iterations)
    h0 = 2.783e-04, Approx. h* = 1.087e-06 (4 iterations)
    h0 = 7.743e-04, Approx. h* = 3.024e-06 (4 iterations)
    h0 = 2.154e-03, Approx. h* = 2.104e-06 (5 iterations)
    h0 = 5.995e-03, Approx. h* = 5.854e-06 (5 iterations)
    h0 = 1.668e-02, Approx. h* = 1.018e-06 (7 iterations)
    h0 = 4.642e-02, Approx. h* = 2.833e-06 (7 iterations)
    h0 = 1.292e-01, Approx. h* = 1.971e-06 (8 iterations)
    h0 = 3.594e-01, Approx. h* = 1.371e-06 (9 iterations)
    h0 = 1.000e+00, Approx. h* = 9.537e-07 (10 iterations)
    Case 2 : Scaled exp




.. GENERATED FROM PYTHON SOURCE LINES 204-216

.. code-block:: Python

    benchmark = nd.ScaledExponentialProblem()
    algorithm = nd.SteplemanWinarsky(benchmark.function, x)
    third_derivative_value = benchmark.third_derivative(benchmark.x)
    optimal_step, absolute_error = nd.FirstDerivativeCentral.compute_step(
        third_derivative_value
    )
    print("Exact h* = %.3e" % (optimal_step))
    print("absolute_error = %.3e" % (absolute_error))
    for h0 in np.logspace(0, 6, 10):
        estim_step, iterations = algorithm.compute_step(h0)
        print("h0 = %.3e, Approx. h* = %.3e (%d iterations)" % (h0, estim_step, iterations))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Exact h* = 6.694e+00
    absolute_error = 2.241e-17
    h0 = 1.000e+00, Approx. h* = 2.500e-01 (1 iterations)
    h0 = 4.642e+00, Approx. h* = 1.160e+00 (1 iterations)
    h0 = 2.154e+01, Approx. h* = 1.347e+00 (2 iterations)
    h0 = 1.000e+02, Approx. h* = 1.562e+00 (3 iterations)
    h0 = 4.642e+02, Approx. h* = 1.813e+00 (4 iterations)
    h0 = 2.154e+03, Approx. h* = 8.416e+00 (4 iterations)
    h0 = 1.000e+04, Approx. h* = 2.441e+00 (6 iterations)
    h0 = 4.642e+04, Approx. h* = 2.833e+00 (7 iterations)
    h0 = 2.154e+05, Approx. h* = 3.287e+00 (8 iterations)
    h0 = 1.000e+06, Approx. h* = 3.815e+00 (9 iterations)





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.889 seconds)


.. _sphx_glr_download_auto_example_plot_stepleman_winarsky_plots.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_stepleman_winarsky_plots.ipynb <plot_stepleman_winarsky_plots.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_stepleman_winarsky_plots.py <plot_stepleman_winarsky_plots.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_stepleman_winarsky_plots.zip <plot_stepleman_winarsky_plots.zip>`
